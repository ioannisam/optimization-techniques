\documentclass[a4paper,12pt]{article}

\usepackage{fontspec}
\usepackage{microtype}
\usepackage{polyglossia}

\setmainlanguage{greek}
\setotherlanguage{english}

\setmainfont{Latin Modern Roman}
\newfontfamily\greekfont{CMU Serif}[Script=Greek]
\newfontfamily\greekfonttt{CMU Typewriter Text}[Script=Greek]

\usepackage[a4paper, top=1.5cm, bottom=1.5cm, left=1.5cm, right=1.5cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{array}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    urlcolor=blue
}
\usepackage[super,sort&compress]{cite}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{Τεχνικές Βελτιστοποίησης: Project}
\author{Ιωάννης Μιχάλαινας ΑΕΜ:10902}
\date{Δεκέμβριος 2025}

\begin{document}

\maketitle

\begin{center}
\textbf{Αποθετήριο Κώδικα:} \\
\href{https://github.com/ioannisam/optimization-techniques}
     {github.com/ioannisam/optimization-techniques}
\end{center}

\bigskip

\begin{abstract}
    Η παρούσα εργασία πραγματεύεται την προσέγγιση μιας άγνωστης μη γραμμικής συνάρτησης δύο μεταβλητών, $f(u_1, u_2)$, μέσω ενός Γενετικού Αλγορίθμου. Στόχος είναι η εύρεση μιας αναλυτικής έκφρασης που αποτελείται από γραμμικό συνδυασμό Γκαουσιανών συναρτήσεων. Ο αλγόριθμος υλοποιήθηκε εξ ολοκλήρου στο MATLAB, χωρίς τη χρήση έτοιμων εργαλείων βελτιστοποίησης. Η διαδικασία περιλαμβάνει την εκπαίδευση του μοντέλου, την επαλήθευση σε νέα δεδομένα για την αποφυγή υπερπροσαρμογής και τέλος, μια διαδικασία απλοποίησης για τη μείωση της πολυπλοκότητας της τελικής έκφρασης.
\end{abstract}

\tableofcontents
\clearpage

\section{Εισαγωγή}
Στο πλαίσιο της παρούσας εργασίας, εξετάζεται το πρόβλημα της εκτίμησης μιας άγνωστης, μη γραμμικής συνάρτησης δύο μεταβλητών $y = f(u_1, u_2)$, βάσει μετρήσεων εισόδου-εξόδου. Η αναλυτική μορφή της $f$ θεωρείται άγνωστη, ενώ είναι γνωστό ότι πρόκειται για συνεχή συνάρτηση των μεταβλητών $u_1$ και $u_2$.

Για την προσέγγιση της $f$, χρησιμοποιείται ένα παραμετρικό μοντέλο που βασίζεται σε γραμμικό συνδυασμό Γκαουσιανών συναρτήσεων βάσης. Συγκεκριμένα, η προσεγγιστική συνάρτηση ορίζεται ως:
\begin{equation}
    \hat f(u_1,u_2) = \sum_{k=1}^{K} G_k(u_1,u_2),
\end{equation}
όπου $K$ είναι το πλήθος των Γκαουσιανών συναρτήσεων. Αρχικά τέθηκε το όριο $K \leq 15$, ωστόσο μέσω διαδικασίας ρύθμισης των παραμέτρων, επιλέχθηκε ως βέλτιστη τιμή $K=6$, όπως αναλύεται αργότερα.
\begin{equation}
    G(u_1, u_2) = w \cdot e^{-\left(\frac{(u_1-c_1)^2}{2\sigma_1^2} + \frac{(u_2-c_2)^2}{2\sigma_2^2}\right)}.
\end{equation}

Η παράμετρος $w$ αποτελεί τον συντελεστή στάθμισης του κάθε Γκαουσιανού όρου, ενώ τα $c_1, c_2$ και $\sigma_1, \sigma_2$ καθορίζουν τη θέση και τη διασπορά του αντίστοιχα. Για κάθε Γκαουσιανή συνάρτηση απαιτείται ο προσδιορισμός πέντε παραμέτρων, με αποτέλεσμα το συνολικό διάνυσμα παραμέτρων να έχει διάσταση $5 \times K$.

Η διαδικασία εκπαίδευσης του μοντέλου πραγματοποιείται μέσω μετρήσεων εισόδου-εξόδου. Για τις ανάγκες παραγωγής των δεδομένων εκπαίδευσης και επαλήθευσης (διακριτά σύνολα), χρησιμοποιείται η συνάρτηση:
\begin{equation}
    f(u_1,u_2) = \sin(u_1 + u_2)\sin(u_2^2),
\end{equation}
με:
\[
    u_1 \in [-1,2], \quad u_2 \in [-2,1].
\]

Στα \textit{Σχήματα \ref{fig:visualization1} και \ref{fig:visualization2}} οπτικοποιείται η συνάρτηση $f(u_1,u_2)$ για διαφορετικό πλήθος δειγμάτων. Παρατηρείται ότι με την αύξηση του αριθμού των σημείων εισόδου-εξόδου καθίσταται σαφέστερη η μορφολογία της συνάρτησης.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/main_1.jpg}
        \caption{Οπτικοποίηση της $f(u_1,u_2)$ \\ (100 δείγματα)}
        \label{fig:visualization1}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/main_2.jpg}
        \caption{Οπτικοποίηση της $f(u_1,u_2)$ \\ (1000 δείγματα)}
        \label{fig:visualization2}
    \end{minipage}
\end{figure}

Λόγω της έντονα μη γραμμικής φύσης του προβλήματος και του μεγάλου αριθμού προς εκτίμηση παραμέτρων, η εύρεση του βέλτιστου διανύσματος παραμέτρων $(w, c_1, \sigma_1, c_2, \sigma_2)$ πραγματοποιείται μέσω ενός Γενετικού Αλγορίθμου, ο οποίος παρουσιάζεται και αναλύεται στην επόμενη ενότητα.

\newpage
\section{Γενετικός Αλγόριθμος}
Οι Γενετικοί Αλγόριθμοι αποτελούν τεχνικές ολικής βελτιστοποίησης. Είναι ευριστικές μέθοδοι βελτιστοποίησης που εμπνέονται από τη διαδικασία της φυσικής επιλογής, η οποία έχει επιδείξει την επιτυχημένη επίλυση πολύπλοκων προβλημάτων βελτιστοποίησης, όπως η δημιουργία και ανάπτυξη νέων οργανισμών. 

Οι Γενετικοί Αλγόριθμοι λειτουργούν πάνω σε έναν πληθυσμό υποψήφιων λύσεων (άτομα), οι οποίες εξελίσσονται μέσω γενετικών τελεστών (επιλογή, διασταύρωση, μετάλλαξη) με στόχο την εύρεση της βέλτιστης λύσης σε πολύπλοκα προβλήματα όπου οι αναλυτικές μέθοδοι είναι δύσκολο να εφαρμοστούν.

Όλοι οι εξελικτικοί αλγόριθμοι θεωρούν έναν πληθυσμό από άτομα (χρωμοσώματα), καθένα από τα οποία αντιπροσωπεύει μία λύση του προβλήματος βελτιστοποίησης. Ο πληθυσμός εξελίσσεται σε γενεές, ως αποτέλεσμα της εφαρμογής διαφόρων εξελικτικών τελεστών. Με αυτό τον τρόπο δημιουργούνται νέα άτομα που παριστάνουν διαφορετικά σημεία στον χώρο αναζήτησης, καλύπτοντας ολοένα και περισσότερες περιοχές αυτού.

Σε κάθε άτομο του πληθυσμού αντιστοιχεί μια τιμή της αντικειμενικής συνάρτησης, η οποία στην ορολογία των εξελικτικών αλγορίθμων καλείται \textit{συνάρτηση ικανότητας} (fitness function). Η διαδικασία επιλογής διασφαλίζει ότι τα άτομα με την καλύτερη απόδοση, η οποία αξιολογείται με βάση τη συνάρτηση ικανότητας, θα έχουν μεγαλύτερη πιθανότητα να επιβιώσουν και να αναπαραχθούν. Κατά συνέπεια, ο πληθυσμός τείνει να εξελιχθεί προς λύσεις με βέλτιστη απόδοση.

Η δημιουργία νέων λύσεων (απογόνων) επιτυγχάνεται κυρίως μέσω δύο μηχανισμών:

\textbf{1. Διασταύρωση:}
Αποτελεί τον κύριο μηχανισμό ανταλλαγής πληροφορίας. Στην παρούσα εργασία, εφαρμόζεται η \textit{Αριθμητική Διασταύρωση}. Δοθέντων δύο γονέων $\mathbf{p}_1$ και $\mathbf{p}_2$, παράγονται δύο απόγονοι $\mathbf{c}_1, \mathbf{c}_2$ μέσω γραμμικού συνδυασμού:
\begin{equation}
    \begin{aligned}
        \mathbf{c}_1 &= \alpha \cdot \mathbf{p}_1 + (1-\alpha) \cdot \mathbf{p}_2 \\
        \mathbf{c}_2 &= (1-\alpha) \cdot \mathbf{p}_1 + \alpha \cdot \mathbf{p}_2
    \end{aligned}
\end{equation}
όπου $\alpha$ είναι ένας τυχαίος αριθμός στο διάστημα $(0,1)$. Η μέθοδος αυτή εξασφαλίζει ότι οι απόγονοι θα βρίσκονται εντός του υπερ-ορθογωνίου που ορίζουν οι γονείς.

\textbf{2. Μετάλλαξη:}
Η μετάλλαξη εισάγει τυχαίες μικρές διαταραχές στα γονίδια των απογόνων, αποτρέποντας την πρόωρη σύγκλιση σε τοπικά ακρότατα. Στην παρούσα υλοποίηση χρησιμοποιείται προσθετικός Γκαουσιανός θόρυβος:
\begin{equation}
    x'_{i} = x_{i} + \delta, \quad \text{όπου } \delta \sim \mathcal{N}(0, \sigma^2)
\end{equation}
όπου $x_i$ η τιμή του γονιδίου και $\delta$ ο θόρυβος που προκύπτει από την κανονική κατανομή με διασπορά που καθορίζεται από την παράμετρο θορύβου (\texttt{mutation\_noise}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{assets/ga.png}
    \caption{Εικονογράφηση των βημάτων ενός Γενετικού Αλγορίθμου\cite{gendesign}}
    \label{fig:ga}
\end{figure}

\subsection{Αλγόριθμος}
Εδώ παρουσιάζεται η παραπάνω διαδικασία του αλγοριθμικά σε ψευδοκώδικα (\textit{Αλγόριθμος \ref{alg:ga}}) και διαγραμματικά (\textit{Σχήμα \ref{fig:flowchart}}).

\begin{algorithm}[H]
    \caption{Γενετικός Αλγόριθμος Βελτιστοποίησης Παραμέτρων}
    \label{alg:ga}
    \begin{algorithmic}[1]
        \Require 
        Μέγεθος πληθυσμού $N$, αριθμός Γκαουσιανών $K$, μέγιστος αριθμός γενεών $MaxGen$, πιθανότητα διασταύρωσης $p_c$, πιθανότητα μετάλλαξης $p_m$
        \Ensure Βέλτιστο διάνυσμα παραμέτρων $\theta_{best}$
        
        \State \textbf{Αρχικοποίηση:} Δημιουργία τυχαίου πληθυσμού $P_0$ μεγέθους $N$ εντός των επιτρεπτών ορίων.
        \State \textbf{Αξιολόγηση:} Υπολογισμός $MSE$ και Fitness $f(x) = \frac{1}{1+MSE(x)}$ για κάθε άτομο $x \in P_0$.
        
        \For{$gen = 1$ \textbf{to} $MaxGen$}
            \State \textbf{Ελιτισμός:} Εντοπισμός και αποθήκευση του καλύτερου ατόμου $x_{best}$ της τρέχουσας γενιάς.
            
            \State \textbf{Επιλογή:} Επιλογή $N$ γονέων από τον $P_{gen-1}$ με τη μέθοδο του Τροχού της Τύχης.
            
            \State \textbf{Διασταύρωση:} Εφαρμογή Διασταύρωσης σε ζεύγη γονέων με πιθανότητα $p_c$.
            
            \State \textbf{Μετάλλαξη:} Εφαρμογή θορύβου στα γονίδια των απογόνων με πιθανότητα $p_m$.
            
            \State \textbf{Επαναφορά Ορίων:} Διόρθωση τιμών που υπερβαίνουν τα όρια αναζήτησης.
            
            \State $P_{gen} \leftarrow$ Απόγονοι.
            \State \textbf{Εισαγωγή Elite:} Αντικατάσταση του πρώτου ατόμου του $P_{gen}$ με το $x_{best}$.
            
            \State \textbf{Αξιολόγηση:} Υπολογισμός Fitness για τον νέο πληθυσμό $P_{gen}$.
        \EndFor
        
        \State \Return Το άτομο με το μέγιστο Fitness από την τελευταία γενιά, $\theta_{best}$.
    \end{algorithmic}
\end{algorithm}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/flowchart.png}
    \caption{Διαγραμματική παρουσίαση του αλγορίθμου\cite{mathworks}}
    \label{fig:flowchart}
\end{figure}

\subsection{Εκπαίδευση}
Στην παρούσα ενότητα περιγράφεται αναλυτικά η διαδικασία που ακολουθήθηκε για την εκπαίδευση του Γενετικού Αλγορίθμου, συμπεριλαμβανομένου του καθορισμού των παραμέτρων και υπερπαραμέτρων, της αρχικοποίησης του πληθυσμού, της κωδικοποίησης των λύσεων, καθώς και της επιλογής και εφαρμογής των γενετικών τελεστών.

\subsubsection{Παράμετροι}
Κατά την εκπόνηση της εργασίας ορίστηκαν ορισμένες παράμετροι και υπερπαράμετροι, η επιλογή των οποίων είναι ιδιαίτερης σημασίας, καθώς επηρεάζουν καθοριστικά τη συμπεριφορά και την απόδοση του αλγορίθμου. Η κατάλληλη ρύθμισή τους επιτρέπει την επίτευξη ικανοποιητικής ισορροπίας μεταξύ ακρίβειας και υπολογιστικής αποδοτικότητας. Οι παράμετροι είναι κεντροποιημένες στο αρχείο \texttt{parameters.m} για την εύκολη διαχείριση και ρύθμισή τους.

Πριν την τελική εκπαίδευση, πραγματοποιήθηκε συστηματική αναζήτηση για τον βέλτιστο καθορισμό των υπερπαραμέτρων. Στον \textit{Πίνακα \ref{tab:parameters}} που ακολουθεί συνοψίζονται οι επιλεγμένες τιμές των παραμέτρων, καθώς και το σκεπτικό που οδήγησε στην επιλογή τους.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|p{7cm}|}
    \hline
    \textbf{Παράμετρος} & \textbf{Τιμή} & \textbf{Περιγραφή / Αιτιολόγηση} \\ \hline
    \texttt{num\_samples} & 1000 & Πλήθος δειγμάτων εκπαίδευσης για επαρκή κάλυψη του πεδίου ορισμού. \\ \hline
    \texttt{c1\_range} & $[-1, 2]$ & Όρια αναζήτησης για τα κέντρα $c_1$, σύμφωνα με το πεδίο ορισμού του $u_1$. \\ \hline
    \texttt{c2\_range} & $[-2, 1]$ & Όρια αναζήτησης για τα κέντρα $c_2$, σύμφωνα με το πεδίο ορισμού του $u_2$. \\ \hline
    \texttt{w\_range} & $[-10, 10]$ & Περιορισμός του εύρους των βαρών για αποφυγή ακραίων τιμών. \\ \hline
    \texttt{sigma\_range} & $[0.2, 2.0]$ & Όρια για το πλάτος των Γκαουσιανών, ώστε να αποφεύγονται τόσο υπερβολικά αιχμηρές όσο και υπερβολικά επίπεδες συναρτήσεις. \\ \hline
    \texttt{pop\_size} & 100 & Μέγεθος πληθυσμού που προσφέρει ισορροπία μεταξύ υπολογιστικού κόστους και ποικιλομορφίας. \\ \hline
    \texttt{num\_gaussians} & 6 & Επιλεγμένος αριθμός Γκαουσιανών όρων βάσει ελαχιστοποίησης του σφάλματος επαλήθευσης. \\ \hline
    \texttt{max\_generations} & 3000 & Μέγιστος αριθμός γενεών για την εξασφάλιση σύγκλισης του αλγορίθμου. \\ \hline
    \texttt{crossover\_rate} & 0.6 & Πιθανότητα διασταύρωσης που επιτρέπει αποτελεσματική εξερεύνηση του χώρου λύσεων χωρίς αστάθεια. \\ \hline
    \texttt{mutation\_rate} & 0.1 & Πιθανότητα μετάλλαξης για διατήρηση της ποικιλομορφίας και αποφυγή πρόωρης σύγκλισης. \\ \hline
    \texttt{mutation\_noise} & 0.05 & Ένταση του θορύβου που προστίθεται κατά τη μετάλλαξη για ελεγχόμενες τοπικές μεταβολές. \\ \hline
    \texttt{pruning\_threshold} & 0.6 & Κατώφλι για την αφαίρεση Γκαουσιανών όρων με μικρή συνεισφορά στο τελικό μοντέλο. \\ \hline
    \end{tabular}
    \caption{Παράμετροι και υπερπαράμετροι του Γενετικού Αλγορίθμου}
    \label{tab:parameters}
\end{table}   

\paragraph{Ρύθμιση Παραμέτρων}\mbox{}\\
Εξετάστηκε η επίδραση της πολυπλοκότητας του μοντέλου στην ακρίβεια πρόβλεψης. Όπως φαίνεται στο \textit{Σχήμα \ref{fig:tune_k}}, δοκιμάστηκαν τιμές $K \in [2, 12]$.
Παρατηρήθηκε ότι για $K=6$, το σφάλμα επαλήθευσης (Validation MSE) ελαχιστοποιείται. Αξίζει να σημειωθεί ότι η αύξηση του $K$ πέραν του 6 δεν οδήγησε σε βελτίωση, αλλά σε αστάθεια, καθώς ο χώρος αναζήτησης γίνεται υπερβολικά πολύπλοκος λόγω της Κατάρας της Διαστατικότητας (Curse of Dimensionality).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{assets/tune_parameters.jpg}
    \caption{MSE ανά αριθμό Γκαουσιανών}
    \label{fig:tune_k}
\end{figure}

\paragraph{Ρύθμιση Υπερπαραμέτρων}\mbox{}\\
Εφαρμόστηκε αναζήτηση πλέγματος (Grid Search) για τον προσδιορισμό των πιθανοτήτων διασταύρωσης ($p_c$) και μετάλλαξης ($p_m$). Τα αποτελέσματα (\textit{Σχήμα \ref{fig:heatmap}}) έδειξαν ότι ο συνδυασμός $p_c=0.6$ και $p_m=0.1$ αποδίδει το χαμηλότερο σφάλμα, επιτρέποντας ικανή εξερεύνηση του χώρου λύσεων χωρίς να διαταράσσεται η σύγκλιση.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{assets/tune_hyperparameters.jpg}
    \caption{Heatmap σφάλματος MSE για διάφορους συνδυασμούς $p_c$ και $p_m$.}
    \label{fig:heatmap}
\end{figure}                                            

\subsubsection{Αρχικοποίηση}
Η διαδικασία ξεκινά με τη δημιουργία ενός αρχικού πληθυσμού $N$ ατόμων (τυπικά 100 άτομα είναι ικανοποιητικά)\cite{book}. Στη συνάρτηση \texttt{initialize\_population} του κώδικα, κάθε γονίδιο του χρωμοσώματος λαμβάνει μια τυχαία τιμή από μια ομοιόμορφη κατανομή εντός των προκαθορισμένων ορίων (\textit{Πίνακας \ref{tab:parameters}}). Αυτό εξασφαλίζει ότι ο αλγόριθμος ξεκινά με μια ευρεία κάλυψη του χώρου αναζήτησης πριν αρχίσει η διαδικασία της εξέλιξης.

\subsubsection{Κωδικοποίηση}
Σε αντίθεση με τους κλασικούς γενετικούς αλγορίθμους που χρησιμοποιούν δυαδική κωδικοποίηση \cite{paper}, στην παρούσα εργασία επιλέχθηκε η κωδικοποίηση πραγματικών αριθμών (real-valued encoding). Κάθε άτομο (χρωμόσωμα) αναπαρίσταται ως ένα διάνυσμα πραγματικών αριθμών που περιέχει τις παραμέτρους των $K=6$ Γκαουσιανών συναρτήσεων.

Συγκεκριμένα, για κάθε Γκαουσιανή $k$, απαιτούνται 5 παράμετροι: το βάρος $w_k$, τα κέντρα $c_{1,k}, c_{2,k}$ και οι τυπικές αποκλίσεις $\sigma_{1,k}, \sigma_{2,k}$. Επομένως, το μήκος του χρωμοσώματος είναι $L = 5 \times 6 = 30$ γονίδια. Η δομή του χρωμοσώματος έχει τη μορφή:
\begin{equation}
    \mathbf{x} = [w_1, c_{1,1}, \sigma_{1,1}, c_{2,1}, \sigma_{2,1}, \dots, w_{6}, c_{1,6}, \sigma_{1,6}, c_{2,6}, \sigma_{2,6}]
\end{equation}

\subsubsection{Συνάρτηση Αξιολόγησης}
Η αξιολόγηση της ποιότητας κάθε λύσης γίνεται μέσω του Μέσου Τετραγωνικού Σφάλματος (MSE) μεταξύ της πραγματικής συνάρτησης $f(u_1, u_2)$ και της εκτίμησης $G(u_1, u_2)$ στα δεδομένα εκπαίδευσης.

Επειδή οι γενετικοί αλγόριθμοι συνήθως μεγιστοποιούν μια συνάρτηση ικανότητας (Fitness Function), ενώ εμείς επιθυμούμε την ελαχιστοποίηση του σφάλματος, χρησιμοποιήθηκε ο ακόλουθος μετασχηματισμός στη συνάρτηση \texttt{fitness}:
\begin{equation}
    Fitness(\mathbf{x}) = \frac{1}{1 + MSE(\mathbf{x})}
\end{equation}
Με αυτόν τον τρόπο, όσο μικρότερο είναι το σφάλμα (MSE $\to$ 0), τόσο η τιμή Fitness πλησιάζει τη μονάδα (μέγιστη τιμή).

\subsubsection{Γενετικοί Τελεστές}
\begin{itemize}
    \item \textbf{Επιλογή (Selection):} Χρησιμοποιήθηκε η μέθοδος του Τροχού της Τύχης (Roulette Wheel Selection). Σύμφωνα με τη μέθοδο αυτή, κάθε άτομο έχει πιθανότητα επιλογής ανάλογη της ικανότητάς του. Η πιθανότητα $P_i$ για το άτομο $i$ υπολογίζεται ως $P_i = \frac{f_i}{\sum_{j=1}^{N} f_j}$, όπου $f_i$ η τιμή της συνάρτησης ικανότητας του ατόμου.
    
    Ωστόσο, καθώς προχωρούν οι γενεές και ο γενετικός αλγόριθμος πλησιάζει στη σύγκλιση, η ικανότητα των ατόμων τείνει να έχει την ίδια περίπου τιμή. Κατά συνέπεια, όλα τα άτομα αποκτούν σχεδόν την ίδια πιθανότητα επιβίωσης και ο γενετικός αλγόριθμος κινδυνεύει να εκφυλιστεί σε μέθοδο τυχαίας αναζήτησης.
    
    Για την επίλυση αυτού του προβλήματος, εφαρμόστηκε \textit{κλιμάκωση} της συνάρτησης ικανότητας, ώστε η υψηλότερη τιμή του τρέχοντος πληθυσμού να απεικονίζεται στο 1 και η χαμηλότερη στο 0 (όπως υλοποιείται στη συνάρτηση \texttt{selection}).
    
    \item \textbf{Διασταύρωση (Crossover):} Εφαρμόστηκε αριθμητική διασταύρωση με πιθανότητα $0.6$. Δύο γονείς $p_1, p_2$ παράγουν απογόνους μέσω γραμμικού συνδυασμού:
    $c_1 = \alpha \cdot p_1 + (1-\alpha) \cdot p_2$ και $c_2 = (1-\alpha) \cdot p_1 + \alpha \cdot p_2$, όπου $\alpha$ τυχαίος αριθμός στο $(0,1)$.
    
    \item \textbf{Μετάλλαξη (Mutation):} Εφαρμόστηκε μετάλλαξη με προσθήκη Γκαουσιανού θορύβου με πιθανότητα $0.1$ ανά γονίδιο. Στις νέες τιμές επιβάλλονται ξανά τα όρια, ώστε να παραμένουν εντός των επιτρεπτών ορίων του προβλήματος.
\end{itemize}

\subsection{Αξιολόγηση}
Μετά την ολοκλήρωση του καθορισμένου αριθμού γενεών (max\_generations), επιλέγεται από τον τελικό πληθυσμό το άτομο με την υψηλότερη τιμή ικανότητας (Elite individual). Αυτό το άτομο αποτελεί τη βέλτιστη λύση που εντόπισε ο αλγόριθμος. Η αξιολόγηση της ποιότητας της λύσης πραγματοποιείται σε τρία επίπεδα:
\begin{enumerate}
    \item \textbf{Υπολογισμός Σφάλματος:} Υπολογίζεται το τελικό Μέσο Τετραγωνικό Σφάλμα (MSE) στα δεδομένα εκπαίδευσης, το οποίο αποτελεί δείκτη της ακρίβειας προσαρμογής του μοντέλου στα γνωστά δεδομένα.
    
    \item \textbf{Έλεγχος Σύγκλισης:} Εξετάζεται το διάγραμμα ιστορικού του σφάλματος (MSE History) ανά γενιά, για να επιβεβαιωθεί ότι ο αλγόριθμος έχει συγκλίνει ομαλά και έχει σταθεροποιηθεί σε μια ελάχιστη τιμή.
    
    \item \textbf{Οπτική Επιθεώρηση:} Δημιουργούνται τρισδιάστατες γραφικές παραστάσεις για την οπτική σύγκριση της επιφάνειας που παράγει η προσεγγιστική συνάρτηση $\hat{f}(u_1, u_2)$ έναντι της πραγματικής συνάρτησης $f(u_1, u_2)$.
\end{enumerate}

\subsubsection{Επαλήθευση}
Για να διασφαλιστεί ότι το μοντέλο δεν έχει υποστεί υπερπροσαρμογή (overfitting) στα δεδομένα εκπαίδευσης, εφαρμόζεται διαδικασία επαλήθευσης. Συγκεκριμένα:
\begin{itemize}
    \item Παράγεται ένα \textbf{νέο σύνολο δεδομένων} $N=1000$ δειγμάτων, χρησιμοποιώντας την ίδια γεννήτρια δεδομένων, αλλά με διαφορετική τυχαία δειγματοληψία εντός του πεδίου ορισμού.
    
    \item Το βέλτιστο μοντέλο αξιολογείται σε αυτό το νέο, άγνωστο σύνολο δεδομένων και υπολογίζεται το Σφάλμα Επαλήθευσης ($MSE_{val}$).
\end{itemize}

Κριτήριο επιτυχίας αποτελεί η σχέση μεταξύ του σφάλματος εκπαίδευσης ($MSE_{train}$) και του σφάλματος επαλήθευσης. Εάν $MSE_{val} \approx MSE_{train}$, τότε το μοντέλο γενικεύει σωστά. Αντιθέτως, αν το $MSE_{val}$ είναι σημαντικά μεγαλύτερο, υπάρχει ένδειξη υπερπροσαρμογής.

\subsubsection{Απλοποίηση}
Στόχος της εργασίας είναι η εύρεση μιας αναλυτικής έκφρασης \textit{χαμηλής πολυπλοκότητας}. Για τον σκοπό αυτό, μετά την εκπαίδευση εφαρμόζεται μια διαδικασία «κλαδέματος» των Γκαουσιανών όρων. Η διαδικασία βασίζεται στο πλάτος (βάρος) $w_k$ κάθε Γκαουσιανής:
\begin{equation}
    \text{Αν } |w_k| < \texttt{pruning\_threshold}, \text{ τότε } w_k = 0
\end{equation}
όπου \texttt{pruning\_threshold} είναι το κατώφλι απλοποίησης που ορίστηκε στις παραμέτρους. Οι όροι με αμελητέα συνεισφορά αφαιρούνται από την τελική έκφραση. Στη συνέχεια, το απλοποιημένο μοντέλο επαναξιολογείται για να διαπιστωθεί εάν η αφαίρεση των όρων προκάλεσε σημαντική αύξηση του σφάλματος. Εάν η αύξηση είναι μικρή, η απλοποιημένη μορφή υιοθετείται ως η τελική λύση.

\newpage
\section{Αποτελέσματα}
Τα παρακάτω αποτελέσματα προέκυψαν τρέχοντας τον αλγόριθμο για \texttt{max\_generation} γενιές.
\subsection{Γραφικές Παραστάσεις}

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{assets/main_3.jpg}
        \caption{Σύγκλιση του αλγορίθμου ανά τις γενιές}
        \label{fig:convergence}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{assets/main_4.jpg}
        \caption{Οπτική σύγκριση της πραγματικής συνάρτησης με την εκτίμηση}
        \label{fig:comparison}
    \end{figure}

\subsection{Ευρήματα}
Ο Γενετικός Αλγόριθμος, μετά τη βελτιστοποίηση των παραμέτρων, κατέληξε σε ένα συμπαγές μοντέλο 6 Γκαουσιανών συναρτήσεων. Τα αποτελέσματα είναι θεαματικά βελτιωμένα σε σχέση με την αρχική προσέγγιση των 15 συναρτήσεων

\begin{itemize}
    \item \textbf{Μείωση Πολυπλοκότητας:} Το μοντέλο χρησιμοποιεί μόλις 30 παραμέτρους (αντί για 75).
    \item \textbf{Βελτίωση Ακρίβειας:} Το MSE επαλήθευσης μειώθηκε στο \textbf{0.00869} (από $\approx 0.017$ με 15 Γκαουσιανές).
    \item \textbf{Βελτίωση Ταχύτητας:} Ο συνολικός χρόνος εκπαίδευσης ανήλθε σε $15.46$ δευτερόλεπτα (προηγουμένως $34+$ δευτερόλεπτα).
\end{itemize}

Στον \textit{Πίνακα \ref{tab:result}} παρουσιάζονται οι παράμετροι των 6 όρων του τελικού μοντέλου. Για μέγιστη ακρίβεια (MSE=0.008) απαιτείται η χρήση και του 6ου όρου που αφαιρέθηκε κατά την απλοποίηση.

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|c|c|r|rr|rr|}
    \hline
    \textbf{k} & \textbf{Ενεργός} & \textbf{$w_k$} & \textbf{$c_{1,k}$} & \textbf{$\sigma_{1,k}$} & \textbf{$c_{2,k}$} & \textbf{$\sigma_{2,k}$} \\ \hline
    1 & Ναι & -0.944 & -0.51 & 0.99 & -0.93 & 0.34 \\
    2 & Ναι &  0.765 &  0.92 & 1.69 & -0.80 & 0.61 \\
    3 & Όχι & -0.482 & -0.05 & 1.34 & -0.20 & 0.96 \\
    4 & Ναι &  1.189 &  0.53 & 1.10 & -0.33 & 1.97 \\
    5 & Ναι & -1.646 &  0.35 & 0.98 & -1.42 & 0.33 \\
    6 & Ναι & -1.253 &  0.73 & 1.04 & -0.26 & 0.60 \\ \hline
    \end{tabular}
    \caption{Οι παράμετροι των 6 Γκαουσιανών όρων του μοντέλου.}
    \label{tab:result}
\end{table}

\subsection{Παρατηρήσεις}
Από την εκπαίδευση, επαλήθευση και ανάλυση των αποτελεσμάτων του Γενετικού Αλγορίθμου προκύπτουν τα ακόλουθα βασικά συμπεράσματα:

\begin{enumerate}
    \item \textbf{Επίδραση Πολυπλοκότητας Μοντέλου:}
    Η χρήση περιορισμένου αριθμού συναρτήσεων βάσης ($K=6$ αντί για $K=15$) οδήγησε σε σαφώς καλύτερη απόδοση. Η μείωση της διάστασης του χώρου αναζήτησης (από 75 σε 30 παραμέτρους) επέτρεψε στον Γενετικό Αλγόριθμο να συγκλίνει ταχύτερα και πιο αξιόπιστα, αποφεύγοντας τοπικά ελάχιστα και φαινόμενα αστάθειας που σχετίζονται με την Κατάρα της Διαστατικότητας.

    \item \textbf{Σύγκλιση Αλγορίθμου:}
    Ο αλγόριθμος παρουσίασε ταχεία μείωση του σφάλματος κατά τις πρώτες γενεές, ενώ στη συνέχεια ακολούθησε φάση σταδιακής βελτίωσης έως τη γενιά 3000. Το τελικό σφάλμα εκπαίδευσης ήταν $MSE_{\text{train}} = 0.00776$, γεγονός που υποδεικνύει επιτυχή προσαρμογή του μοντέλου στα δεδομένα εκπαίδευσης.

    \item \textbf{Ικανότητα Γενίκευσης:}
    Η αξιολόγηση σε ανεξάρτητο σύνολο δεδομένων επαλήθευσης απέδωσε $MSE_{\text{val}} = 0.00869$, τιμή πολύ κοντινή στο σφάλμα εκπαίδευσης. Η μικρή αυτή απόκλιση καταδεικνύει ότι το μοντέλο δεν έχει υποστεί υπερπροσαρμογή και γενικεύει ικανοποιητικά σε άγνωστα δεδομένα.

    \item \textbf{Απλοποίηση Μοντέλου:}
    Εφαρμόστηκε διαδικασία απλοποίησης με κατώφλι βάρους $|w| < 0.6$. Καθώς αφαιρέθηκε ένας από τους έξι Γκαουσιανούς όρους (Active Gaussians: 5), παρατηρήθηκε σημαντική αύξηση του σφάλματος επαλήθευσης (από $0.00869$ σε $0.08606$). Το αποτέλεσμα αυτό υποδεικνύει ότι και οι έξι όροι είναι ουσιώδεις για την ακριβή περιγραφή της συνάρτησης και ότι το μοντέλο των $K=6$ όρων επιτυγχάνει βέλτιστη ισορροπία μεταξύ ακρίβειας και απλότητας.

    \item \textbf{Χρόνος Εκτέλεσης:}
    Η μείωση του μήκους του χρωμοσώματος και η κατάλληλη ρύθμιση των υπερπαραμέτρων οδήγησαν σε σημαντική μείωση του χρόνου εκτέλεσης, καθιστώντας τη μέθοδο αποδοτική και κατάλληλη ακόμη και για εφαρμογές με αυξημένες χρονικές απαιτήσεις.
\end{enumerate}

\newpage
\appendix

\section{Εργαλεία}
Τα εργαλεία που χρησιμοποιήθηκαν κατά την εκπόνηση της εργασίας είναι τα εξής:
\begin{itemize}
    \item MATLAB
    \item LaTeX
    \item Git
\end{itemize}

\begin{thebibliography}{9}

    \bibitem[\href{https://www.tziola.gr/book/rovi/}{1}]{book}
    Γ. Ροβιθάκης, \textit{Τεχνικές Βελτιστοποίησης}, Εκδόσεις Τζιόλα, 2007.
    
    \bibitem[\href{https://www2.fiit.stuba.sk/~kvasnicka/Free\%20books/Goldberg_Genetic_Algorithms_in_Search.pdf}{2}]{paper}
    D. E. Goldberg, \textit{Genetic Algorithms in Search, Optimization, and Machine Learning}. Reading, MA: Addison-Wesley, 1989.
    
    \bibitem[\href{https://www.mathworks.com/help/gads/what-is-the-genetic-algorithm.html}{3}]{mathworks}
    MathWorks, What Is the Genetic Algorithm?, \textit{MathWorks Documentation}.
    
    \bibitem[\href{https://medium.com/@sanskar4862/how-to-generate-a-genetic-algorithm-with-matlab-6dbc595d54c8}{4}]{medium}
    S. Sanskar, How to Generate a Genetic Algorithm with MATLAB, \textit{Medium}, Dec. 2024.
    
    \bibitem[\href{https://www.generativedesign.org/02-deeper-dive/02-04_genetic-algorithms}{5}]{gendesign}
    Generative Design, Genetic Algorithms, \textit{Generative Design Library}.

\end{thebibliography}

\end{document}